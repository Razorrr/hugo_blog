<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on (*´･д･)?</title>
    <link>http://xrazor.org/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on (*´･д･)?</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 21 Nov 2016 23:21:28 +0800</lastBuildDate>
    
	<atom:link href="http://xrazor.org/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>信息熵、信息增益和Gini指数</title>
      <link>http://xrazor.org/post/%E4%BF%A1%E6%81%AF%E7%86%B5%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E5%92%8Cgini%E6%8C%87%E6%95%B0/</link>
      <pubDate>Mon, 21 Nov 2016 23:21:28 +0800</pubDate>
      
      <guid>http://xrazor.org/post/%E4%BF%A1%E6%81%AF%E7%86%B5%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E5%92%8Cgini%E6%8C%87%E6%95%B0/</guid>
      <description>在机器学习决策树中，引入里熵、信息增益、信息增益比和Gini指数，作为特征选择的准则。不同的算法对应了不同的特征选择准则，如ID3选用信息增益的大小作为特征选择判定的标准，C4.5则选用信息增益比为选择标准，CART则用Gini指数作为选择标准。那么，所引入的这几个指标的内涵意义是什么呢？本文将作一个简单的梳理。
信息熵 在信息论里面，熵被用来衡量一个随机变量出现的期望值，对不确定性的测量，是描述一个系统所需的最低存储单元。在信息世界，熵越高，所需传递的信息越丰富，熵越低，则意味着所需传输的信息越少。而在热力学里，熵越高，表示混乱度越高。 这三个解释乍一看毫无关联，实际上确实可以相互印证的。以抛硬币为例，自然条件下结果为正面或反面的概率均为50%， 此时结果的不确定性最高， 越混乱，而我们要描述这个结果所需的文字（暂且用文字的个数代表存储单元）越多，比如你会这么描述“结果可能是正面，也可能是反面”（加逗号14个字）；而当我们假定正面出现的概率为100%时，信息熵为0，不混乱很清晰，而此时我们描述这个结果所需的存储单元是很少的，比如说“是正面”（3个字）就能描述清楚。
信息增益 有了上面的概念，我们就可以结合ID3算法来看看信息增益是什么东西。 在ID3中，使用信息增益作为特征选择的准则，用H（D）表示数据集的经验熵，用H（D|A)表示在A特征下数据集D的经验条件熵，则信息增益g（D，A）= H(D) - H(D|A), 表示 有A 和 没A ，整个系统的不确定性变化了多少。这里要牢记， 熵高，是说明不确定很大，如果H（D）很大，而 H（D|A)很小，则g（D,A）会趋大， 说明特征A 的存在，大大降低了系统的不确定性， 因此它是一个关键的特征。
Gini指数 Gini指数是CART算法中生成分类树时用来选择特征的一个指标。</description>
    </item>
    
  </channel>
</rss>