<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>实做CNN手写数字辨识 - (*´･д･)?</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="xrazor" />
  <meta name="description" content="开始 语言：Python2 框架：Keras Backend: tensorflow OS: Archlinux Package: numpy,pandas,seaborn,sklearn,etc Method: CPU(i7) 数据集: MNIST 模型结构： In -&amp;gt; [[Conv2D-&amp;gt;relu]*2 -&amp;gt; MaxPool2D -&amp;gt; Dropout]*2 -&amp;gt; Flatten -&amp;gt; Dense -&amp;gt; Dropout -&amp;gt; Out. 现在让我们在Ipython里面跑。" />

  <meta name="keywords" content="hack, 机器学习, python" />






<meta name="generator" content="Hugo 0.32.4" />


<link rel="canonical" href="http://xrazor.org/post/%E5%AE%9E%E5%81%9Acnn%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%BE%A8%E8%AF%86/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">







<link href="/dist/even.min.css?v=3.1.1" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="实做CNN手写数字辨识" />
<meta property="og:description" content="开始 语言：Python2 框架：Keras Backend: tensorflow OS: Archlinux Package: numpy,pandas,seaborn,sklearn,etc Method: CPU(i7) 数据集: MNIST 模型结构： In -&gt; [[Conv2D-&gt;relu]*2 -&gt; MaxPool2D -&gt; Dropout]*2 -&gt; Flatten -&gt; Dense -&gt; Dropout -&gt; Out. 现在让我们在Ipython里面跑。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://xrazor.org/post/%E5%AE%9E%E5%81%9Acnn%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%BE%A8%E8%AF%86/" />



<meta property="article:published_time" content="2017-06-25T23:04:01&#43;08:00"/>

<meta property="article:modified_time" content="2017-06-25T23:04:01&#43;08:00"/>











<meta itemprop="name" content="实做CNN手写数字辨识">
<meta itemprop="description" content="开始 语言：Python2 框架：Keras Backend: tensorflow OS: Archlinux Package: numpy,pandas,seaborn,sklearn,etc Method: CPU(i7) 数据集: MNIST 模型结构： In -&gt; [[Conv2D-&gt;relu]*2 -&gt; MaxPool2D -&gt; Dropout]*2 -&gt; Flatten -&gt; Dense -&gt; Dropout -&gt; Out. 现在让我们在Ipython里面跑。">


<meta itemprop="datePublished" content="2017-06-25T23:04:01&#43;08:00" />
<meta itemprop="dateModified" content="2017-06-25T23:04:01&#43;08:00" />
<meta itemprop="wordCount" content="3755">



<meta itemprop="keywords" content="机器学习&#34;," />
<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="实做CNN手写数字辨识"/>
<meta name="twitter:description" content="开始 语言：Python2 框架：Keras Backend: tensorflow OS: Archlinux Package: numpy,pandas,seaborn,sklearn,etc Method: CPU(i7) 数据集: MNIST 模型结构： In -&gt; [[Conv2D-&gt;relu]*2 -&gt; MaxPool2D -&gt; Dropout]*2 -&gt; Flatten -&gt; Dense -&gt; Dropout -&gt; Out. 现在让我们在Ipython里面跑。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Xrazor</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Rencent</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/skilltree/">
        <li class="mobile-menu-item">SkillTree</li>
      </a><a href="/bookmarks/">
        <li class="mobile-menu-item">BookMarks</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="/contact/">
        <li class="mobile-menu-item">Contact</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Xrazor</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Rencent</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/skilltree/">SkillTree</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/bookmarks/">BookMarks</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/contact/">Contact</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">实做CNN手写数字辨识</h1>

      <div class="post-meta">
        <span class="post-time"> 2017-06-25 </span>
        
        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="#开始">开始</a></li>
<li><a href="#数据预处理">数据预处理</a>
<ul>
<li>
<ul>
<li><a href="#import各种包">import各种包</a></li>
<li><a href="#载入数据">载入数据</a></li>
<li><a href="#检查空值-缺失值">检查空值/缺失值</a></li>
<li><a href="#归一化">归一化</a></li>
<li><a href="#reshape">Reshape</a></li>
<li><a href="#对labels进行one-hot编码">对labels进行one-hot编码</a></li>
<li><a href="#划分训练集和验证集-validation-set">划分训练集和验证集(validation set)</a></li>
</ul></li>
</ul></li>
<li><a href="#训练模型">训练模型</a>
<ul>
<li>
<ul>
<li><a href="#cnn">CNN</a></li>
<li><a href="#优化器">优化器</a></li>
<li><a href="#数据增强-data-augmentation">数据增强(Data augmentation)</a></li>
<li><a href="#是时候train一发了">是时候train一发了</a></li>
</ul></li>
</ul></li>
<li><a href="#模型评估">模型评估</a>
<ul>
<li>
<ul>
<li><a href="#画loss和acc曲线">画loss和acc曲线</a></li>
<li><a href="#画混淆矩阵-confusion-matrix">画混淆矩阵(Confusion Matrix)</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      

<h1 id="开始">开始</h1>

<div align=center><img src="http://markdown0327.oss-cn-beijing.aliyuncs.com/18-3-18/3017240.jpg"/></div> 

<ul>
<li>语言：Python2</li>
<li>框架：Keras</li>
<li>Backend: tensorflow</li>
<li>OS: Archlinux</li>
<li>Package: numpy,pandas,seaborn,sklearn,etc</li>
<li>Method: CPU(i7)</li>
<li>数据集: MNIST</li>
</ul>

<p>模型结构：</p>

<pre><code>In -&gt; [[Conv2D-&gt;relu]*2 -&gt; MaxPool2D -&gt; Dropout]*2 -&gt; Flatten -&gt; Dense -&gt; Dropout -&gt; Out.
</code></pre>

<p>现在让我们在Ipython里面跑。</p>

<h1 id="数据预处理">数据预处理</h1>

<h3 id="import各种包">import各种包</h3>

<pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns

np.random.seed(2) # seed中使用数字相同，则每次程序中生成的随机数都相同

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import itertools

from keras.utils.np_utils import to_categorical # convert to one-hot-encoding
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D
from keras.optimizers import RMSprop
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau 

sns.set(style='white', context='notebook', palette='deep')
</code></pre>

<h3 id="载入数据">载入数据</h3>

<pre><code class="language-python">train = pd.read_csv(&quot;../data/train.csv&quot;)
test = pd.read_csv(&quot;../data/test.csv&quot;)
</code></pre>

<pre><code class="language-python">Y_train = train[&quot;label&quot;]
X_train = train.drop(labels = [&quot;label&quot;],axis = 1) 

g = sns.countplot(Y_train) # 看一看各标签大致分布情况
Y_train.value_counts() 
</code></pre>

<div align=center><img src="http://markdown0327.oss-cn-beijing.aliyuncs.com/18-3-18/32508221.jpg"/></div>

<p>总共0-9 10个数字，可以看出分布都差不多。</p>

<h3 id="检查空值-缺失值">检查空值/缺失值</h3>

<p>mnist是处理好的数据集，不会有缺失的情况，但是这个检查步骤要形成习惯。</p>

<pre><code class="language-python">X_train.isnull().any().describe()
</code></pre>

<h3 id="归一化">归一化</h3>

<p>mnist是黑白的，因此这里做的是灰度归一化(grey scale),归一化的作用有2个：</p>

<ul>
<li>减小照度带来的差异</li>
<li>加快模型训练速度</li>
</ul>

<pre><code class="language-python">X_train = X_train / 255.0
test = test / 255.0
</code></pre>

<h3 id="reshape">Reshape</h3>

<pre><code class="language-python">X_train = X_train.values.reshape(-1,28,28,1)
test = test.values.reshape(-1,28,28,1)
</code></pre>

<p>pandas 导进来的数据是784长度的1D vector， 我们要将其转为28 * 28 的3D metrices, 因为是黑白图片所以通道数只有1， 如果是彩色的，则RGB通道就是3.</p>

<h3 id="对labels进行one-hot编码">对labels进行one-hot编码</h3>

<p>keras里面自带的就有，直接用。</p>

<pre><code class="language-python">Y_train = to_categorical(Y_train, num_classes = 10) # (ex : 2 -&gt; [0,0,1,0,0,0,0,0,0,0])
</code></pre>

<p>one-hot的作用在于：它使距离计算或相似度计算更合理了。</p>

<h3 id="划分训练集和验证集-validation-set">划分训练集和验证集(validation set)</h3>

<p>这里用sklearn的方法，很方便。</p>

<pre><code class="language-python">random_seed = 2
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state=random_seed)
</code></pre>

<p>这里训练集和验证集是8:2， 注意：这里是随机分，能随机分的前提是各个labels的分布比较均匀， 对于一些有偏斜的类，直接像上面这样random可能结果会变得很糟糕，应对之法是在train_test_split中多加一个参数stratify，它使validation之后的分布仍和之前的分布一样。</p>

<h1 id="训练模型">训练模型</h1>

<h3 id="cnn">CNN</h3>

<p>这里keras的后端用的是tensorflow，众所周知采用的是先架“管道”后通“水”的运作方式，先定义图，再将数据导入。
对于CNN模型的搭建，我们使用keras中的Sequential API操作，搭建的方式也非常符合”直觉“，需要什么层就按顺序添加就好。
再来看看我们之前说的神经网络结构：</p>

<pre><code>In -&gt; [[Conv2D-&gt;relu]*2 -&gt; MaxPool2D -&gt; Dropout]*2 -&gt; Flatten -&gt; Dense -&gt; Dropout -&gt; Out
</code></pre>

<p>CNN有”四大神兽“：</p>

<ul>
<li>先是<strong>卷积层</strong>(convelutional layer)。卷积层有几个核心的参数需要设定，一是filters的数量，每一个filters都会学习某一种特征，比如说有的学“撇”、有的学“捺”、有的学”竖“&hellip;， 而到了第二个卷积层的时候所学的特征就会比第一层卷积更”高级“， 比如说已经可以学习到一些连笔之类的， 这些filters学出来的东西又组合成一个矩阵叫feature map，供下一层作为input。总之我们这里前后各有2个卷积层，前面的filters是32个，后面的是64个。</li>
<li>第二是<strong>池化层</strong>(pooling layer), 它的作用是一个下采样器（downsampling）,比如一个size是(2, 2)的maxpooling filter就是从一个2*2的方块中选出最大的那个数字，然后移动到下一个方块，maxpooling filter的移动一般是不overlap的。它的作用一是减少参数，加快训练；二是减少过拟合几率，增强泛化能力。</li>
<li>三是<strong>Dropout层</strong>（不知道怎么翻译），这是一个正则化的方法，在CNN的开山论文中被提出，作用是减少过拟合，它的工作就是按概率让神经网络中的某些神经元失效。</li>
<li>最后是<strong>激活层</strong>(activation layer), 它为整个神经网络引入非线性的特征，我们这里用的是ReLU(max(0, x))。</li>
</ul>

<p>另外， flatten 层的作用是把前一层卷积/池化得到的featuremap展平成1维， 让后面的全连接层可以用。
最后我们用softmax来输出各分类的概率。</p>

<pre><code class="language-python">model = Sequential()

model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', 
                 activation ='relu', input_shape = (28,28,1)))
model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', 
                 activation ='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', 
                 activation ='relu'))
model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', 
                 activation ='relu'))
model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation = &quot;relu&quot;))
model.add(Dropout(0.5))
model.add(Dense(10, activation = &quot;softmax&quot;))
</code></pre>

<h3 id="优化器">优化器</h3>

<p>机器学习方法= 模型+策略+算法， 现在模型已经搞定了，还剩策略和算法。策略是指如何评价一个模型的好坏，算法是指我们怎么计算能够又快又好的找到一个解。具体地，就是要定义loss function和optimization算法, optimization 一定是能不断减小loss function的。
这里我们的loss function选用交叉熵, 即categorical_crossentropy, 优化算法选RMSprop，比SGD高效。</p>

<pre><code class="language-python">optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)
# 编译模型
model.compile(optimizer = optimizer , loss = &quot;categorical_crossentropy&quot;, metrics=[&quot;accuracy&quot;])
</code></pre>

<p>这样模型就编译好了。</p>

<p><strong>One more thing&hellip;</strong>
为了让优化器收敛更快， 我们需要对一个关键参数——学习率（learning rate）用退火法处理。原理上来说，学习率越大，参数更新得越快，然而事实是有时候步子迈大了容易陷入一个局部最小的趋于， 在里面来回逛。因此我们需要一个逐步变小的学习率。怎么变呢？如果正确率不再提高，那么我们设定3个周期后自动将学习率将至原来的一半。这里通过调用ReduceLROnPlateau方法可以实现。这是一个回调函数，回调函数就是在迭代过程中某一时刻会按条件触发的函数。</p>

<pre><code class="language-python">learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', # 监测指标
                                            patience=3, # 等待周期
                                            verbose=1, 
                                            factor=0.5, # 每次衰减幅度
                                            min_lr=0.00001 # 学习率下限)
</code></pre>

<p>这里我们同时设立一下epoch和batch，batch就是一次看多少个样本，epoch就是一个batch看几遍。</p>

<pre><code class="language-python">epochs = 15
batch_size = 86
</code></pre>

<h3 id="数据增强-data-augmentation">数据增强(Data augmentation)</h3>

<p>为了增强模型的泛化能力，我们希望它能多看一下数据，但是原本的数据就这么大，怎么办呢，我们可以在原本的数据集上做一些微小的改动，给他们增加一些noise，这样就等于有了更多的feature。这个是一个压箱底的”大杀器“，使用后可明显提高性能。常用的Data augmentation包括但不限于：</p>

<ul>
<li>灰度缩放grayscales</li>
<li>水平翻转horizontal flips</li>
<li>垂直翻转vertical flips</li>
<li>随机裁剪random crops</li>
<li>颜色抖动color jitters</li>
<li>旋转rotations</li>
</ul>

<p>还是调用现成的方法：</p>

<pre><code class="language-python">datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)
        zoom_range = 0.1, # Randomly zoom image 
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images

datagen.fit(X_train)
</code></pre>

<p>我们这里采用的有那么几招：</p>

<ul>
<li>随机旋转10°</li>
<li>随机缩放10%</li>
<li>随机水平拉伸10%</li>
<li>随机垂直拉伸10%</li>
</ul>

<h3 id="是时候train一发了">是时候train一发了</h3>

<p>把刚才的退火法lr回调函数写进callbacks里，train之。</p>

<pre><code class="language-python">history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),
                              epochs = epochs, validation_data = (X_val,Y_val),
                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size
                              , callbacks=[learning_rate_reduction])
</code></pre>

<p>注意这里用的是model.fit_generator, 如果是model.fit就是直接把数据一把load进内存中，这个对于使用gpu计算的情况，数据集太大的话有可能会把显存撑爆。
接下来让我们看一看结果&gt;&gt;&gt;&gt;&gt;</p>

<pre><code> - 110s - loss: 0.5793 - acc: 0.8131 - val_loss: 0.0908 - val_acc: 0.9712
Epoch 2/15
 - 103s - loss: 0.1894 - acc: 0.9434 - val_loss: 0.0935 - val_acc: 0.9678
Epoch 3/15
 - 103s - loss: 0.1374 - acc: 0.9585 - val_loss: 0.0380 - val_acc: 0.9886
Epoch 4/15
 - 106s - loss: 0.1070 - acc: 0.9685 - val_loss: 0.0457 - val_acc: 0.9853
Epoch 5/15
 - 104s - loss: 0.0958 - acc: 0.9711 - val_loss: 0.0387 - val_acc: 0.9886
Epoch 6/15
 - 104s - loss: 0.0888 - acc: 0.9747 - val_loss: 0.0354 - val_acc: 0.9909
Epoch 7/15
 - 104s - loss: 0.0761 - acc: 0.9766 - val_loss: 0.0399 - val_acc: 0.9893
Epoch 8/15
 - 104s - loss: 0.0806 - acc: 0.9757 - val_loss: 0.0289 - val_acc: 0.9919
Epoch 9/15
 - 104s - loss: 0.0703 - acc: 0.9797 - val_loss: 0.0328 - val_acc: 0.9886
Epoch 10/15
 - 104s - loss: 0.0695 - acc: 0.9791 - val_loss: 0.0378 - val_acc: 0.9899
Epoch 11/15
 - 104s - loss: 0.0686 - acc: 0.9803 - val_loss: 0.0314 - val_acc: 0.9914
Epoch 12/15

Epoch 00012: reducing learning rate to 0.000500000023749.
 - 104s - loss: 0.0633 - acc: 0.9801 - val_loss: 0.0329 - val_acc: 0.9907
Epoch 13/15
 - 104s - loss: 0.0519 - acc: 0.9853 - val_loss: 0.0257 - val_acc: 0.9929
Epoch 14/15
 - 104s - loss: 0.0523 - acc: 0.9848 - val_loss: 0.0276 - val_acc: 0.9912
Epoch 15/15
 - 104s - loss: 0.0514 - acc: 0.9856 - val_loss: 0.0295 - val_acc: 0.9932

</code></pre>

<p>没用gpu，跑了半个多小时，这里我们train了15个epoch，loss和acc是训练集上的，val_loss和val_acc是验证集上的，可以看到一开始训练集比验证集上的acc要差，这是因为我们做了data augmentation，导致看训练集识别的难度有所提升。另外在epoch=12时触发了回调函数，调整了学习率，最终我们的acc在验证集上做到了0.9932，勉强可以，如果epoch更高应该会有更好的表现，这里为了节省时间只跑了15个epoch。</p>

<h1 id="模型评估">模型评估</h1>

<h3 id="画loss和acc曲线">画loss和acc曲线</h3>

<pre><code class="language-python">fig, ax = plt.subplots(2,1)
ax[0].plot(history.history['loss'], color='b', label=&quot;Training loss&quot;)
ax[0].plot(history.history['val_loss'], color='r', label=&quot;validation loss&quot;,axes =ax[0])
legend = ax[0].legend(loc='best', shadow=True)

ax[1].plot(history.history['acc'], color='b', label=&quot;Training accuracy&quot;)
ax[1].plot(history.history['val_acc'], color='r',label=&quot;Validation accuracy&quot;)
legend = ax[1].legend(loc='best', shadow=True)
</code></pre>

<p><div align=center><img src="http://markdown0327.oss-cn-beijing.aliyuncs.com/18-3-18/64903322.jpg"/></div>
在15个epoch里面，validation set 的acc一直略微高于training set的，说明没有过拟合，模型训练得不错。</p>

<h3 id="画混淆矩阵-confusion-matrix">画混淆矩阵(Confusion Matrix)</h3>

<p>混淆矩阵的一轴表示预测下的分类样本数，另一轴表示实际的分类样本数，通过混淆矩阵我们可以直观的判断哪些地方误分类较为严重。这里我们选用validation set的数据来做。</p>

<pre><code class="language-python">def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    &quot;&quot;&quot;
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    &quot;&quot;&quot;
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment=&quot;center&quot;,
                 color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;)

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

# Predict the values from the validation dataset
Y_pred = model.predict(X_val)
# Return the biggest num's index.
Y_pred_classes = np.argmax(Y_pred,axis = 1) 

Y_true = np.argmax(Y_val,axis = 1) 
# compute the confusion matrix
confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) 
# plot the confusion matrix
plot_confusion_matrix(confusion_mtx, classes = range(10)) 
</code></pre>

<p><div align=center><img src="http://markdown0327.oss-cn-beijing.aliyuncs.com/18-3-18/60901388.jpg"/></div>
从混淆矩阵可以看出，大多数分类都还ok，只有9相对比较差，容易被误分为4。
让我们进一步看一看错误的典型。</p>

<pre><code class="language-python"># get errors bool array
errors = (Y_pred_classes - Y_true != 0)
# check which class is misclassification
Y_pred_classes_errors = Y_pred_classes[errors]
Y_pred_errors = Y_pred[errors]
Y_true_errors = Y_true[errors]
X_val_errors = X_val[errors]

def display_errors(errors_index,img_errors,pred_errors, obs_errors):
    &quot;&quot;&quot; This function shows 6 images with their predicted and real labels&quot;&quot;&quot;
    n = 0
    nrows = 2
    ncols = 3
    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)
    for row in range(nrows):
        for col in range(ncols):
            error = errors_index[n]
            ax[row,col].imshow((img_errors[error]).reshape((28,28)))
            ax[row,col].set_title(&quot;Predicted label :{}\nTrue label :{}&quot;.format(pred_errors[error],obs_errors[error]))
            n += 1

# Probabilities of the wrong predicted numbers
Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)

# Predicted probabilities of the true values in the error set
true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))

# Difference between the probability of the predicted label and the true label
delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors

# Sorted list of the delta prob errors
sorted_dela_errors = np.argsort(delta_pred_true_errors)

# Top 6 errors 
most_important_errors = sorted_dela_errors[-6:]

# Show the top 6 errors
display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)
</code></pre>

<p>好了，这里我们就找出来top6的错误：
<div align=center><img src="http://markdown0327.oss-cn-beijing.aliyuncs.com/18-3-18/16765960.jpg"/></div>
简直坑爹，那几个true label是9的人都会认错有木有，所以我们模型表现还是不错的。
OK, 今天就先到这里了。</p>

    </div>

    
    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">xrazor</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">2017-06-25</span>
  </p>
  
  
</div>

    
    

    <footer class="post-footer">
      <div class="post-tags">
          
          <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习&#34;</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/%E5%A6%82%E4%BD%95%E8%AF%84%E4%BB%B7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%A5%BD%E5%9D%8F/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">如何评价模型的好坏</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/impala&#43;spark%E6%93%8D%E4%BD%9C%E5%AE%9E%E8%B7%B5/">
            <span class="next-text nav-default">Impala&#43;Spark操作实践</span>
            <span class="prev-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
      <a href="http://localhost:1313" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="http://localhost:1313" class="iconfont icon-twitter" title="twitter"></a>
      <a href="http://localhost:1313" class="iconfont icon-facebook" title="facebook"></a>
      <a href="http://localhost:1313" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="http://localhost:1313" class="iconfont icon-google" title="google"></a>
      <a href="http://localhost:1313" class="iconfont icon-github" title="github"></a>
      <a href="http://localhost:1313" class="iconfont icon-weibo" title="weibo"></a>
      <a href="http://localhost:1313" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="http://localhost:1313" class="iconfont icon-douban" title="douban"></a>
      <a href="http://localhost:1313" class="iconfont icon-pocket" title="pocket"></a>
      <a href="http://localhost:1313" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="http://localhost:1313" class="iconfont icon-instagram" title="instagram"></a>
  <a href="http://xrazor.org/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    
      2017 - 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">xrazor</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>
<script type="text/javascript" src="/dist/even.min.js?v=3.1.1"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>


<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-113190132-2', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>







</body>
</html>
